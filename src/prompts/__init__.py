"""
Module des prompts pour les agents du Refactoring Swarm.

Ce module contient les prompts systÃ¨me pour :
- Agent Auditeur (analyse de code)
- Agent Correcteur (correction de bugs)
- Agent Testeur (validation par tests)

Auteur: IngÃ©nieur Prompt
Date: 2026-01-10
Version: 1.0
"""

from .auditor_prompt import get_auditor_prompt, get_auditor_metadata
from .fixer_prompt import get_fixer_prompt, get_fixer_metadata
from .judge_prompt import get_judge_prompt, get_judge_metadata

__version__ = "1.0.0"
__author__ = "IngÃ©nieur Prompt"

__all__ = [
    "get_auditor_prompt",
    "get_auditor_metadata",
    "get_fixer_prompt",
    "get_fixer_metadata",
    "get_judge_prompt",
    "get_judge_metadata",
    "PROMPT_VERSIONS",
    "ESTIMATED_COSTS",
    "get_module_info",
    "print_module_info",
]

# ============================================================
# MÃ‰TADONNÃ‰ES DES VERSIONS
# ============================================================

PROMPT_VERSIONS = {
    "auditor": {
        "version": "1.0",
        "date": "2026-01-08",
        "status": "validated",
        "model": "gemini-2.5-flash",
        "detection_rate": "113%",
        "false_positive_rate": "0%",
        "description": "DÃ©tecte les bugs dans le code Python avec une prÃ©cision exceptionnelle",
    },
    "fixer": {
        "version": "1.0",
        "date": "2026-01-09",
        "status": "validated",
        "model": "gemini-2.5-flash",
        "correction_rate": "100%",
        "syntax_valid_rate": "100%",
        "description": "Corrige tous les bugs dÃ©tectÃ©s en prÃ©servant la structure du code",
    },
    "judge": {
        "version": "1.0",
        "date": "2026-01-09",
        "status": "validated",
        "model": "gemini-2.5-flash",
        "decision_accuracy": "100%",
        "description": "Analyse les rÃ©sultats pytest et dÃ©cide de valider ou renvoyer au correcteur",
    },
}

# ============================================================
# ESTIMATION DES COÃ›TS (en tokens)
# ============================================================

ESTIMATED_COSTS = {
    "auditor": {
        "input_tokens_avg": 1200,
        "output_tokens_avg": 600,
        "total_tokens_avg": 1800,
        "time_avg_seconds": 4,
        "cost_note": "Gratuit avec Gemini Flash",
    },
    "fixer": {
        "input_tokens_avg": 5500,
        "output_tokens_avg": 800,
        "total_tokens_avg": 6300,
        "time_avg_seconds": 6,
        "cost_note": "Gratuit avec Gemini Flash",
    },
    "judge": {
        "input_tokens_avg": 800,
        "output_tokens_avg": 150,
        "total_tokens_avg": 950,
        "time_avg_seconds": 2,
        "cost_note": "Gratuit avec Gemini Flash",
    },
    "total_workflow": {
        "total_tokens_avg": 9050,
        "time_avg_seconds": 12,
        "cost_note": "Pour un workflow complet : Audit -> Fix -> Judge",
    },
}

# ============================================================
# FONCTIONS UTILITAIRES
# ============================================================


def get_module_info() -> dict:
    """
    Retourne les informations complÃ¨tes du module.
    
    Returns:
        dict: Informations sur le module (version, agents, coÃ»ts, statuts)
    
    Example:
        >>> info = get_module_info()
        >>> print(info['version'])
        1.0.0
        >>> print(info['all_validated'])
        True
    """
    return {
        "version": __version__,
        "author": __author__,
        "agents": list(PROMPT_VERSIONS.keys()),
        "all_validated": all(
            v["status"] == "validated" for v in PROMPT_VERSIONS.values()
        ),
        "prompt_versions": PROMPT_VERSIONS,
        "estimated_costs": ESTIMATED_COSTS,
    }


def print_module_info() -> None:
    """
    Affiche les informations du module dans la console de maniÃ¨re formatÃ©e.
    
    Utile pour vÃ©rifier rapidement l'Ã©tat du module et les mÃ©triques.
    
    Example:
        >>> print_module_info()
        ================================================================================
        ğŸ¤– MODULE DE PROMPTS - REFACTORING SWARM
        ...
    """
    info = get_module_info()
    
    print("=" * 80)
    print("ğŸ¤– MODULE DE PROMPTS - REFACTORING SWARM")
    print("=" * 80)
    print(f"ğŸ“¦ Version      : {info['version']}")
    print(f"ğŸ‘¤ Auteur       : {info['author']}")
    print(f"ğŸ¤– Agents       : {', '.join(info['agents'])}")
    print(f"âœ… Tous validÃ©s : {'Oui' if info['all_validated'] else 'Non'}")
    
    print("\n" + "â”€" * 80)
    print("ğŸ“Š MÃ‰TRIQUES PAR AGENT")
    print("â”€" * 80)
    
    for agent, data in PROMPT_VERSIONS.items():
        print(f"\nğŸ”¹ {agent.upper()}")
        print(f"   Version     : {data['version']}")
        print(f"   Status      : {data['status']}")
        print(f"   ModÃ¨le      : {data['model']}")
        print(f"   Description : {data['description']}")
        
        if agent == "auditor":
            print(f"   DÃ©tection   : {data['detection_rate']}")
            print(f"   Faux positifs : {data['false_positive_rate']}")
        elif agent == "fixer":
            print(f"   Correction  : {data['correction_rate']}")
            print(f"   Syntaxe valide : {data['syntax_valid_rate']}")
        elif agent == "judge":
            print(f"   PrÃ©cision   : {data['decision_accuracy']}")
    
    print("\n" + "â”€" * 80)
    print("ğŸ’° COÃ›TS MOYENS (TOKENS)")
    print("â”€" * 80)
    
    for agent, costs in ESTIMATED_COSTS.items():
        if agent == "total_workflow":
            print(f"\nğŸ¯ WORKFLOW COMPLET")
            print(f"   Total tokens : ~{costs['total_tokens_avg']}")
            print(f"   Temps moyen  : ~{costs['time_avg_seconds']}s")
            print(f"   Note         : {costs['cost_note']}")
        else:
            print(f"\n   {agent.upper()}")
            print(f"      Input   : ~{costs['input_tokens_avg']} tokens")
            print(f"      Output  : ~{costs['output_tokens_avg']} tokens")
            print(f"      Total   : ~{costs['total_tokens_avg']} tokens")
            print(f"      Temps   : ~{costs['time_avg_seconds']}s")
    
    print("\n" + "=" * 80)
    print("âœ… Module prÃªt pour l'intÃ©gration !")
    print("=" * 80 + "\n")


# ============================================================
# GUIDE RAPIDE POUR L'ORCHESTRATEUR
# ============================================================

def print_quick_guide() -> None:
    """
    Affiche un guide rapide d'utilisation pour l'Orchestrateur.
    """
    guide = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                        GUIDE RAPIDE - ORCHESTRATEUR                        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ğŸ“š IMPORTS
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    from src.prompts import get_auditor_prompt, get_fixer_prompt, get_judge_prompt
    import google.generativeai as genai
    
    ğŸ”§ CONFIGURATION
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
    model = genai.GenerativeModel('gemini-2.5-flash')
    
    ğŸ”„ WORKFLOW DE BASE
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    # 1. AUDIT
    prompt = get_auditor_prompt(filename, code)
    response = model.generate_content(prompt)
    audit_report = json.loads(response.text)
    
    # 2. FIX
    prompt = get_fixer_prompt(filename, code, audit_report)
    response = model.generate_content(prompt)
    fixed_code = response.text
    
    # 3. TEST
    prompt = get_judge_prompt(filename, pytest_output)
    response = model.generate_content(prompt)
    judge_report = json.loads(response.text)
    
    ğŸ“– DOCUMENTATION COMPLÃˆTE
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Voir : docs/prompts/GUIDE_ORCHESTRATEUR.md
    
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(guide)


# Si exÃ©cutÃ© directement, affiche les infos
if __name__ == "__main__":
    print_module_info()
    print("\n")
    print_quick_guide()
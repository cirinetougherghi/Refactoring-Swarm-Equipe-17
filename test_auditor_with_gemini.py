"""
Script de test manuel pour l'Agent Auditeur
Test avec Gemini 2.5 Flash sur les fichiers bugg√©s
"""

import os
import json
from dotenv import load_dotenv
import google.generativeai as genai
from src.prompts.auditor_prompt import get_auditor_prompt
# ‚úÖ AJOUT DATA OFFICER : Import du syst√®me de logging
from src.utils.logger import log_experiment, ActionType

# Charge les variables d'environnement
load_dotenv()

# Configure l'API Gemini
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("‚ùå ERREUR : Cl√© API non trouv√©e dans .env")
    exit(1)

genai.configure(api_key=api_key)


def test_auditor_on_file(file_path: str):
    """
    Teste l'Auditeur sur un fichier sp√©cifique.
    
    Args:
        file_path (str): Chemin vers le fichier √† analyser
    """
    print("=" * 80)
    print(f"üîç TEST SUR : {file_path}")
    print("=" * 80)
    
    # 1. Lit le fichier
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            code_content = f.read()
    except FileNotFoundError:
        print(f"‚ùå Fichier non trouv√© : {file_path}")
        return
    
    file_name = os.path.basename(file_path)
    print(f"üìÑ Fichier : {file_name}")
    print(f"üìè Lignes de code : {len(code_content.splitlines())}")
    
    # 2. G√©n√®re le prompt avec la fonction helper
    print("\n‚öôÔ∏è  G√©n√©ration du prompt...")
    prompt = get_auditor_prompt(file_name, code_content)
    print(f"‚úÖ Prompt g√©n√©r√© ({len(prompt)} caract√®res, ~{len(prompt)//4} tokens)")
    
    # 3. Envoie √† Gemini
    print("\nü§ñ Envoi √† Gemini 2.5 Flash...")
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = model.generate_content(prompt)
        raw_response = response.text
        
        print(f"‚úÖ R√©ponse re√ßue ({len(raw_response)} caract√®res)")
           # ‚úÖ AJOUT DATA OFFICER : Log de l'interaction r√©ussie avec Gemini
        log_experiment(
            agent_name="Auditor_Agent",
            model_used="gemini-2.5-flash",
            action=ActionType.ANALYSIS,
            details={
                "file_analyzed": file_name,
                "input_prompt": prompt,
                "output_response": raw_response,
                "prompt_length_chars": len(prompt),
                "response_length_chars": len(raw_response),
                "code_lines_analyzed": len(code_content.splitlines())
            },
            status="SUCCESS"
        )
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'appel API : {e}")
         # ‚úÖ AJOUT DATA OFFICER : Log de l'erreur API
        log_experiment(
            agent_name="Auditor_Agent",
            model_used="gemini-2.5-flash",
            action=ActionType.ANALYSIS,
            details={
                "file_analyzed": file_name,
                "input_prompt": prompt,
                "output_response": "",
                "error_type": type(e).__name__,
                "error_message": str(e)
            },
            status="ERROR"
        )
        return
    
    # 4. Affiche la r√©ponse brute
    print("\n" + "=" * 80)
    print("üì® R√âPONSE BRUTE DE GEMINI :")
    print("=" * 80)
    print(raw_response)
    print("=" * 80)
    
    # 5. Tente de parser le JSON
    print("\nüîç ANALYSE DE LA R√âPONSE :")
    
    # Nettoie la r√©ponse (enl√®ve les balises markdown si pr√©sentes)
    cleaned_response = raw_response.strip()
    if cleaned_response.startswith("```json"):
        cleaned_response = cleaned_response[7:]  # Enl√®ve ```json
    if cleaned_response.startswith("```"):
        cleaned_response = cleaned_response[3:]  # Enl√®ve ```
    if cleaned_response.endswith("```"):
        cleaned_response = cleaned_response[:-3]  # Enl√®ve ```
    cleaned_response = cleaned_response.strip()
    
    # Tente de parser le JSON
    try:
        result = json.loads(cleaned_response)
        print("‚úÖ JSON VALIDE !")

         # ‚úÖ AJOUT DATA OFFICER : Log enrichi avec r√©sultats du parsing
        issues = result.get('issues', [])
        log_experiment(
            agent_name="Auditor_Agent",
            model_used="gemini-2.5-flash",
            action=ActionType.ANALYSIS,
            details={
                "file_analyzed": file_name,
                "input_prompt": prompt,
                "output_response": raw_response,
                "parsing_status": "SUCCESS",
                "json_valid": True,
                "total_issues_found": result.get('total_issues', 0),
                "issues_breakdown": {
                    "critical": sum(1 for i in issues if i.get('severity') == 'CRITICAL'),
                    "major": sum(1 for i in issues if i.get('severity') == 'MAJOR'),
                    "minor": sum(1 for i in issues if i.get('severity') == 'MINOR')
                }
            },
            status="SUCCESS"
        )

        # Affiche les r√©sultats
        print(f"\nüìä R√âSULTATS :")
        print(f"   Fichier analys√© : {result.get('file', 'N/A')}")
        print(f"   Total de probl√®mes : {result.get('total_issues', 0)}")
        
        issues = result.get('issues', [])
        
        if issues:
            print(f"\nüêõ BUGS D√âTECT√âS ({len(issues)}) :")
            for i, issue in enumerate(issues, 1):
                print(f"\n   [{i}] Ligne {issue.get('line', '?')}")
                print(f"       Type : {issue.get('type', 'N/A')}")
                print(f"       S√©v√©rit√© : {issue.get('severity', 'N/A')}")
                print(f"       Description : {issue.get('description', 'N/A')}")
                print(f"       Suggestion : {issue.get('suggestion', 'N/A')}")
        else:
            print("\n‚ú® Aucun probl√®me d√©tect√© - Code propre !")
        
        # Sauvegarde le r√©sultat
        output_file = f"test_results_{file_name.replace('.py', '')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nüíæ R√©sultat sauvegard√© dans : {output_file}")
        
    except json.JSONDecodeError as e:
        print(f"‚ùå ERREUR : JSON INVALIDE !")
        print(f"   Erreur : {e}")
        print(f"\n‚ö†Ô∏è  PROBL√àME : Gemini a ajout√© du texte avant/apr√®s le JSON")
          # ‚úÖ AJOUT DATA OFFICER : Log de l'√©chec du parsing
        log_experiment(
            agent_name="Auditor_Agent",
            model_used="gemini-2.5-flash",
            action=ActionType.ANALYSIS,
            details={
                "file_analyzed": file_name,
                "input_prompt": prompt,
                "output_response": raw_response,
                "parsing_status": "FAILED",
                "json_valid": False,
                "parsing_error_type": type(e).__name__,
                "parsing_error_message": str(e)
            },
            status="PARTIAL"
        )
        print(f"   ou le JSON est mal form√©.")
        
        # Sauvegarde la r√©ponse brute pour analyse
        error_file = f"test_error_{file_name.replace('.py', '')}.txt"
        with open(error_file, 'w', encoding='utf-8') as f:
            f.write(raw_response)
        print(f"\nüíæ R√©ponse brute sauvegard√©e dans : {error_file}")
    
    print("\n" + "=" * 80)


def main():
    """Fonction principale - teste plusieurs fichiers"""
    
    print("\n" + "üß™" * 40)
    print("TEST DE L'AGENT AUDITEUR AVEC GEMINI 2.5 FLASH")
    print("üß™" * 40 + "\n")
    
    # Liste des fichiers √† tester
    test_files = [
         "sandbox/test_samples/buggy_code_simple.py",  
         "sandbox/test_samples/buggy_code_medium.py", 
         "sandbox/test_samples/buggy_code_complex.py",
         "sandbox/test_samples/buggy_code_edge_cases.py",
    ]
    
    for file_path in test_files:
        test_auditor_on_file(file_path)
        print("\n")
    
    print("‚úÖ TESTS TERMIN√âS !\n")
    print("\nüìä Les logs d'exp√©rimentation ont √©t√© enregistr√©s dans logs/experiment_data.json")
    print("üí° Lancez 'python validate_logs.py' pour valider le format des logs\n")

if __name__ == "__main__":
    main()